python init_tokenizer.py --source_tokenizer_dir=meta-llama/Llama-2-7b-hf --target_tokenizer_dir=target_tokenizer --expand_tokens_file=vocab.txt
